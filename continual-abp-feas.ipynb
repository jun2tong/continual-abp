{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import resnet\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as tutils\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision.transforms as tv_transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.datasets as tv_datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from gen_model import FeaturesGenerator, InferenceQYZ\n",
    "from sklearn import preprocessing\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesGenerator(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, num_k, out_dim):\n",
    "        self.num_nodes = latent_dim + num_k\n",
    "        super(FeaturesGenerator, self).__init__()\n",
    "        self.main = nn.Sequential(nn.Linear(self.num_nodes, 512),\n",
    "                                  nn.LeakyReLU(0.2, True),\n",
    "                                  nn.Linear(512, out_dim),\n",
    "#                                   nn.ReLU(True),\n",
    "                                  nn.Sigmoid()\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        in_vec = torch.cat([x, y], dim=1)\n",
    "        out = self.main(in_vec)\n",
    "        return out\n",
    "\n",
    "\n",
    "class LinearCLS(nn.Module):\n",
    "    def __init__(self, input_dim, nclass):\n",
    "        super(LinearCLS, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, nclass)\n",
    "        self.logic = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, x): \n",
    "        o = self.logic(self.fc(x))\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Time Feature Extraction\n",
    "\n",
    "Using Resnet56 from, https://github.com/akamaster/pytorch_resnet_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(resnet.resnet56())\n",
    "checkpoint = torch.load(\"pretrained_weights/resnet56-4bfd9763.th\")            \n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(device)\n",
    "# model.module.linear = nn.Identity()\n",
    "# fc_cls = model.module.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(data_path, file_list):\n",
    "    data = []\n",
    "    targets = []\n",
    "    # now load the picked numpy arrays\n",
    "    for file_name, checksum in file_list:\n",
    "        file_path = f\"{data_path}/{file_name}\"\n",
    "        with open(file_path, 'rb') as f:\n",
    "            entry = pickle.load(f, encoding='latin1')\n",
    "            data.append(entry['data'])\n",
    "            if 'labels' in entry:\n",
    "                targets.extend(entry['labels'])\n",
    "            else:\n",
    "                targets.extend(entry['fine_labels'])\n",
    "    data = np.vstack(data).reshape(-1, 3, 32, 32)\n",
    "    data = data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "train_list = [\n",
    "    ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "    ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "    ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "    ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "    ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "]\n",
    "test_list = [\n",
    "    ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "]\n",
    "\n",
    "x_train, y_train = read_pickle(\"data/cifar-10-batches-py/\",train_list)\n",
    "x_valid, y_valid = read_pickle(\"data/cifar-10-batches-py/\",test_list)\n",
    "\n",
    "x_train = torch.from_numpy(x_train.astype(\"float32\")).permute(0,3,1,2)\n",
    "x_valid = torch.from_numpy(x_valid.astype(\"float32\")).permute(0,3,1,2)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_trans = tv_transforms.Compose([\n",
    "                                   tv_transforms.ToPILImage(),\n",
    "                                   tv_transforms.Resize(32),\n",
    "                                   tv_transforms.ToTensor(),\n",
    "                                   tv_transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                           std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "alst = []\n",
    "for idx in range(x_train.shape[0]):\n",
    "    img = img_trans(x_train[idx])\n",
    "    alst.append(img.unsqueeze(0))\n",
    "x_train = torch.cat(alst, dim=0)\n",
    "\n",
    "alst = []\n",
    "for idx in range(x_valid.shape[0]):\n",
    "    img = img_trans(x_valid[idx])\n",
    "    alst.append(img.unsqueeze(0))\n",
    "x_valid = torch.cat(alst, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.38999938964844\n"
     ]
    }
   ],
   "source": [
    "mb_size = 128\n",
    "num_iter = x_valid.size(0) // mb_size\n",
    "bd_indices = [ii for ii in range(0, x_valid.size(0), mb_size)]\n",
    "batch_indices = np.arange(x_valid.size(0))\n",
    "corr = 0\n",
    "with torch.no_grad():\n",
    "    for idx, iter_count in enumerate(bd_indices):\n",
    "        batch_idx = batch_indices[iter_count:iter_count+mb_size]\n",
    "        x_mb = x_valid[batch_idx].float().to(device)\n",
    "        y_mb = y_valid[batch_idx]\n",
    "        output = model.module.linear(x_mb)\n",
    "        pred = torch.argmax(output,dim=1)\n",
    "        corr += torch.sum(torch.eq(y_mb, pred.cpu()))\n",
    "\n",
    "acc = 100*corr / float(x_valid.size(0))\n",
    "print(f\"accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 128\n",
    "model.eval()\n",
    "train_feas = []\n",
    "with torch.no_grad():\n",
    "    for idx in np.arange(0, x_train.size(0), mb_size):\n",
    "        x_mb = x_train[idx:idx+mb_size].to(device)\n",
    "        feas_out = model.module.get_feas(x_mb)\n",
    "        train_feas.append(feas_out.detach())\n",
    "\n",
    "    train_feas = torch.cat(train_feas, dim=0)\n",
    "    \n",
    "test_feas = []\n",
    "with torch.no_grad():\n",
    "    for idx in np.arange(0, x_valid.size(0), mb_size):\n",
    "        x_mb = x_valid[idx:idx+mb_size].to(device)\n",
    "        feas_out = model.module.get_feas(x_mb)\n",
    "        test_feas.append(feas_out.detach())\n",
    "\n",
    "    test_feas = torch.cat(test_feas, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"x_train\": train_feas.cpu().detach(),\n",
    "            \"x_valid\": test_feas.cpu().detach(),\n",
    "            \"y_train\": torch.from_numpy(y_train).long(),\n",
    "            \"y_valid\": torch.from_numpy(y_valid).long()}, \"data/cifar-10-batches-py/resnet56_midfeas_unnorm.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"data/cifar-10-batches-py/resnet56_feas.tar\")\n",
    "x_train = checkpoint[\"x_train\"].numpy()\n",
    "x_valid = checkpoint[\"x_valid\"].numpy()\n",
    "# x_train = checkpoint[\"x_train\"]\n",
    "# x_valid = checkpoint[\"x_valid\"]\n",
    "y_train = checkpoint['y_train']\n",
    "y_valid = checkpoint[\"y_valid\"]\n",
    "\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_valid = scaler.transform(x_valid)\n",
    "x_train = torch.from_numpy(x_train)\n",
    "x_valid = torch.from_numpy(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Upper Bound Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 128\n",
    "linear_cls = LinearCLS(64, 10).to(device)\n",
    "optimizer_cls = torch.optim.Adam(linear_cls.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "cls_criterion = nn.NLLLoss()\n",
    "\n",
    "num_iter = x_train.size(0) // mb_size\n",
    "bd_indices = [ii for ii in range(0, x_train.size(0), mb_size)]\n",
    "\n",
    "for epc in range(20):\n",
    "    batch_indices = np.random.permutation(np.arange(x_train.size(0)))\n",
    "    for idx, iter_count in enumerate(bd_indices):\n",
    "        batch_idx = batch_indices[iter_count:iter_count+mb_size]\n",
    "        x_mb = x_train[batch_idx].float().to(device)\n",
    "        y_mb = y_train[batch_idx].to(device)\n",
    "        output = linear_cls(x_mb)\n",
    "        loss = cls_criterion(output, y_mb)\n",
    "        optimizer_cls.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_cls.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = x_valid.size(0) // mb_size\n",
    "bd_indices = [ii for ii in range(0, x_valid.size(0), mb_size)]\n",
    "batch_indices = np.arange(x_valid.size(0))\n",
    "corr = 0\n",
    "with torch.no_grad():\n",
    "    for idx, iter_count in enumerate(bd_indices):\n",
    "        batch_idx = batch_indices[iter_count:iter_count+mb_size]\n",
    "        x_mb = x_valid[batch_idx].float().to(device)\n",
    "        y_mb = y_valid[batch_idx].to(device)\n",
    "        output = linear_cls(x_mb)\n",
    "        pred = torch.argmax(output,dim=1)\n",
    "        corr += torch.sum(torch.eq(y_mb, pred))\n",
    "\n",
    "acc = 100*corr / float(x_valid.size(0))\n",
    "print(f\"accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_mask_1 = y_train >= 4\n",
    "task_mask_2 = y_train < 6\n",
    "task_mask = task_mask_1 * task_mask_2\n",
    "\n",
    "train_feas = x_train[task_mask]\n",
    "train_label = y_train[task_mask]\n",
    "\n",
    "task_mask_1 = y_valid >= 0\n",
    "task_mask_2 = y_valid < 6\n",
    "task_mask = task_mask_1 * task_mask_2\n",
    "valid_feas = x_valid[task_mask]\n",
    "valid_label = y_valid[task_mask]\n",
    "print(f\"train X: {train_feas.shape}\")\n",
    "print(f\"train Y : {train_label.shape}\")\n",
    "print(f\"valid X: {valid_feas.shape}\")\n",
    "print(f\"valid Y: {valid_label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feas = torch.cat([gen_feat, train_feas], dim=0)\n",
    "train_label = torch.cat([gen_label, train_label])\n",
    "print(f\"train X: {train_feas.shape}\")\n",
    "print(f\"train Y : {train_label.shape}\")\n",
    "print(f\"valid X: {valid_feas.shape}\")\n",
    "print(f\"valid Y: {valid_label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "#         nn.init.kaiming_normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.kaiming_normal_(m.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "def get_recon_loss(pred, x, sigma):\n",
    "    recon_loss = 1/(2*sigma**2) * torch.pow(x - pred, 2).sum()\n",
    "    return recon_loss\n",
    "\n",
    "\n",
    "def get_prior_loss(z, mus, logsigma):\n",
    "    log_pdf = 0.5 * torch.sum(np.log(2.0 * np.pi) + logsigma + torch.pow(z - mus, 2) / torch.exp(logsigma))\n",
    "    return log_pdf\n",
    "\n",
    "\n",
    "def get_prior_loss_mm(z, mus, logsigma):\n",
    "    dist_term = torch.pow(z.unsqueeze(1) - mus.unsqueeze(0), 2) / torch.exp(logsigma.unsqueeze(0))\n",
    "    log_pdf = -0.5 * torch.sum(np.log(2.0 * np.pi) + logsigma.unsqueeze(0) + dist_term, dim=-1)  # (B, nc)\n",
    "    return log_pdf\n",
    "\n",
    "\n",
    "def get_entropy_loss(logits, probs):\n",
    "    log_q = torch.log_softmax(logits, dim=1)\n",
    "    return torch.sum(-torch.sum(probs * log_q, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 10\n",
    "num_k = 10\n",
    "mb_size = 64\n",
    "lr_rate = 0.0002\n",
    "weight_decay = 0.001\n",
    "langevin_s = 0.3\n",
    "langevin_steps = 30\n",
    "sigma = 0.3\n",
    "\n",
    "train_z = torch.FloatTensor(train_feas.shape[0], latent_dim).normal_(0,1).float().to(device)\n",
    "mus = torch.FloatTensor(num_k, latent_dim).normal_(0,5).float().to(device)\n",
    "mus.requires_grad_()\n",
    "logsigma = torch.zeros(num_k, latent_dim).float().to(device)\n",
    "logsigma.requires_grad_()\n",
    "# pi_c = torch.ones(num_k)/num_k\n",
    "# pi_c = pi_c.float().to(device)\n",
    "# pi_c.requires_grad_()\n",
    "\n",
    "netG = FeaturesGenerator(latent_dim, num_k, 64).to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "num_iter = train_feas.size(0) // mb_size\n",
    "bd_indices = [ii for ii in range(0,train_feas.size(0), mb_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_z = torch.FloatTensor(train_feas.shape[0], latent_dim).normal_(0,1).float().to(device)\n",
    "train_z[:replay_z.size(0)] = replay_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('cifar10feas_task1.tar')\n",
    "\n",
    "netG.load_state_dict(checkpoint[\"netG_state_dict\"])\n",
    "train_z = checkpoint['train_z_state'].to(device)\n",
    "mus = checkpoint[\"mus\"].to(device)\n",
    "logsigma = checkpoint[\"logsigma\"].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimizer_g = torch.optim.Adam(list(netG.parameters()) + list(netD.parameters()), lr=lr_rate, weight_decay=weight_decay, betas=(0.5,0.999))\n",
    "optimizer_g = torch.optim.Adam(netG.parameters(), lr=lr_rate, weight_decay=weight_decay, betas=(0.5,0.999))\n",
    "optimizer_g.add_param_group({\"params\": [mus, logsigma]})\n",
    "\n",
    "for epc in range(20):\n",
    "    batch_indices = np.random.permutation(np.arange(train_feas.size(0)))\n",
    "    epc_loss = 0\n",
    "    for idx, iter_count in enumerate(bd_indices):\n",
    "        batch_idx = batch_indices[iter_count:iter_count+mb_size]\n",
    "        x_mb = train_feas[batch_idx].float().to(device)\n",
    "        y_mb = train_label[batch_idx]\n",
    "        z_mb = train_z[batch_idx]\n",
    "        z_mb.requires_grad_()\n",
    "        optimizer_z = torch.optim.Adam([z_mb], lr=lr_rate, weight_decay=weight_decay, betas=(0.5,0.999))\n",
    "        batch_loss = 0\n",
    "        for em in range(2):\n",
    "            optimizer_g.zero_grad()\n",
    "            one_hot_y = torch.eye(num_k)[y_mb]\n",
    "            recon_x = netG(z_mb, one_hot_y.to(device))\n",
    "            recon_loss = get_recon_loss(recon_x, x_mb, sigma)  # Reconstruction Loss\n",
    "\n",
    "            log_pdfs = get_prior_loss_mm(z_mb, mus, logsigma)\n",
    "#             y_cat = torch.argmax(log_pdfs, dim=1).detach()\n",
    "            yita_c = torch.exp(log_pdfs) + 1e-10\n",
    "            yita_c = yita_c/torch.sum(yita_c, dim=1).view(-1,1)\n",
    "            entropy_loss = get_entropy_loss(log_pdfs, one_hot_y.to(device))  # Entropy Loss\n",
    "            \n",
    "            prior_loss = get_prior_loss(z_mb, mus[y_mb], logsigma[y_mb])\n",
    "#             prior_loss = 0.5*torch.sum(torch.pow(z_mb, 2))\n",
    "            \n",
    "            gloss = recon_loss + prior_loss + entropy_loss\n",
    "            gloss /= x_mb.size(0)\n",
    "            gloss.backward()\n",
    "            optimizer_g.step()\n",
    "            srmc_loss = 0\n",
    "            for _ in range(langevin_steps):\n",
    "                optimizer_z.zero_grad()\n",
    "                u_tau = torch.randn(z_mb.size(0), latent_dim).float().to(device)\n",
    "\n",
    "                one_hot_y = torch.eye(num_k)[y_mb]\n",
    "                recon_x = netG(z_mb, one_hot_y.to(device))\n",
    "                recon_loss = get_recon_loss(recon_x, x_mb, sigma)\n",
    "                \n",
    "                log_pdfs = get_prior_loss_mm(z_mb, mus, logsigma)\n",
    "                y_cat = torch.argmax(log_pdfs, dim=1).detach()\n",
    "                yita_c = torch.exp(log_pdfs) + 1e-10\n",
    "                yita_c = yita_c/torch.sum(yita_c, dim=1).view(-1,1)\n",
    "                entropy_loss = get_entropy_loss(log_pdfs, one_hot_y.to(device)) \n",
    "            \n",
    "                prior_loss = get_prior_loss(z_mb, mus[y_mb], logsigma[y_mb])\n",
    "#                 prior_loss = 0.5*torch.sum(torch.pow(z_mb, 2))\n",
    "                \n",
    "                loss = recon_loss + prior_loss + entropy_loss\n",
    "                loss /= x_mb.size(0)\n",
    "                loss = langevin_s**2/2*loss\n",
    "                loss.backward()\n",
    "                optimizer_z.step()\n",
    "                z_mb.data += u_tau * langevin_s\n",
    "                srmc_loss += loss.detach()\n",
    "                \n",
    "            train_z[batch_idx,] = z_mb.data\n",
    "            batch_loss += (srmc_loss / langevin_steps) + gloss.detach()\n",
    "        batch_loss /= 2\n",
    "        epc_loss += batch_loss\n",
    "    print(f\"Epoch {epc+1} End; loss: {(epc_loss/(idx+1)): .4f}; recon: {recon_loss: .4f}; prior: {prior_loss: .4f}; entropy: {entropy_loss: .4f}\")\n",
    "#     print(f\"Epoch {epc+1} End; loss: {(epc_loss/(idx+1)): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'netG_state_dict': netG.state_dict(),\n",
    "#             'netD_state_dict': netD.state_dict(),\n",
    "            'train_z_state': train_z.cpu().detach(),\n",
    "            'mus': mus.cpu().detach(),\n",
    "            'logsigma':logsigma.cpu().detach()\n",
    "            }, \"cifar10feas_task1.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model 1 (Not run)\n",
    "\n",
    "Short-run MC for the latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 64\n",
    "test_size = valid_feas.size(0)\n",
    "corr = 0\n",
    "corr_1 = 0\n",
    "\n",
    "# Maybe deep copy the weights\n",
    "for batch_idx in range(0, test_size, mb_size):\n",
    "    x_new = valid_feas[batch_idx:batch_idx+mb_size].to(device)\n",
    "    y_new = valid_label[batch_idx:batch_idx+mb_size].to(device)\n",
    "\n",
    "    z_samp = torch.randn(x_new.size(0),latent_dim).to(device)\n",
    "    optim_new = torch.optim.Adam(netG.parameters(), lr=lr_rate, weight_decay=weight_decay, betas=(0.5,0.999))\n",
    "    optim_new.add_param_group({\"params\": [z_samp]})\n",
    "#     optim_new = torch.optim.Adam([z_samp], lr=lr_rate, weight_decay=weight_decay, betas=(0.5,0.999))\n",
    "\n",
    "    for _ in range(50):\n",
    "        recon_x = netG(z_samp, 1)\n",
    "        recon_loss = get_recon_loss(recon_x, x_new, sigma)\n",
    "        loss = (recon_loss)/y_new.shape[0]\n",
    "        loss = langevin_s**2/2*loss\n",
    "        optim_new.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_new.step()\n",
    "    recon_feas = netG(z_samp,1)\n",
    "    pred_cls = torch.argmax(fc_cls(recon_feas), dim=1).detach()\n",
    "    orig_pred = torch.argmax(fc_cls(x_new), dim=1).detach()\n",
    "    num_correct = torch.sum(torch.eq(pred_cls, y_new))\n",
    "    corr += num_correct\n",
    "    num_correct = torch.sum(torch.eq(orig_pred, y_new))\n",
    "    corr_1 += num_correct\n",
    "    \n",
    "acc = corr / float(test_size)\n",
    "print(f\"Inferential Backprop: {acc*100: .4f}\")\n",
    "acc = corr_1 / float(test_size)\n",
    "print(f\"Original weights: {acc*100: .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model 2\n",
    "\n",
    "Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training samples\n",
    "nSample = 300\n",
    "gen_feat = torch.FloatTensor(6 * nSample, 64)\n",
    "gen_label = np.zeros([0])\n",
    "replay_z = []\n",
    "with torch.no_grad():\n",
    "    for ii in range(6):\n",
    "        one_hot_y = torch.eye(num_k)[ii]\n",
    "        one_hot_y = one_hot_y.repeat(nSample, 1)\n",
    "        z = torch.randn(nSample, latent_dim).to(device)\n",
    "        G_sample = netG(z, one_hot_y.to(device))\n",
    "        gen_feat[ii*nSample:(ii+1)*nSample] = G_sample\n",
    "        gen_label = np.hstack((gen_label, np.ones([nSample])*ii))\n",
    "        replay_z.append(z)\n",
    "\n",
    "gen_label = torch.from_numpy(gen_label).long()\n",
    "replay_z = torch.cat(replay_z, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "mb_size = 128\n",
    "linear_cls = LinearCLS(64, 10).to(device)\n",
    "optimizer_cls = torch.optim.Adam(linear_cls.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "cls_criterion = nn.NLLLoss()\n",
    "\n",
    "num_iter = gen_feat.size(0) // mb_size\n",
    "bd_indices = [ii for ii in range(0, gen_feat.size(0), mb_size)]\n",
    "\n",
    "for epc in range(20):\n",
    "    batch_indices = np.random.permutation(np.arange(gen_feat.size(0)))\n",
    "    for idx, iter_count in enumerate(bd_indices):\n",
    "        batch_idx = batch_indices[iter_count:iter_count+mb_size]\n",
    "        x_mb = gen_feat[batch_idx].float().to(device)\n",
    "        y_mb = gen_label[batch_idx].to(device)\n",
    "        output = linear_cls(x_mb)\n",
    "        loss = cls_criterion(output, y_mb)\n",
    "        optimizer_cls.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_cls.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "num_iter = valid_feas.size(0) // mb_size\n",
    "bd_indices = [ii for ii in range(0, valid_feas.size(0), mb_size)]\n",
    "batch_indices = np.arange(valid_feas.size(0))\n",
    "corr = 0\n",
    "with torch.no_grad():\n",
    "    for idx, iter_count in enumerate(bd_indices):\n",
    "        batch_idx = batch_indices[iter_count:iter_count+mb_size]\n",
    "        x_mb = valid_feas[batch_idx].float().to(device)\n",
    "        y_mb = valid_label[batch_idx].to(device)\n",
    "        output = linear_cls(x_mb)\n",
    "        pred = torch.argmax(output,dim=1)\n",
    "        corr += torch.sum(torch.eq(y_mb, pred))\n",
    "\n",
    "acc = 100*corr / float(valid_feas.size(0))\n",
    "print(f\"accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "latent_rep = train_z.cpu().numpy()\n",
    "embed = TSNE(n_components=2).fit_transform(latent_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "mask0 = train_label.numpy() == 0\n",
    "mask1 = train_label.numpy() == 1\n",
    "plt.scatter(embed[mask0,0], embed[mask0,1])\n",
    "plt.scatter(embed[mask1,0], embed[mask1,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
